{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fbf5ddf",
   "metadata": {},
   "source": [
    "# Querying notebooks with SQL\n",
    "\n",
    "*Added in sklearn-evaluation version 0.6*. Questions? [Join our community!](https://ploomber.io/community)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b479191",
   "metadata": {},
   "source": [
    "`NotebookDatabase` indexes outputs from a collection of notebooks in a SQLite database so you can query them. Any tagged cells will be captured and indexed by the database.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "```sh\n",
    "pip install scikit-learn sklearn-evaluation ploomber jupysql\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# to train models in parallel\n",
    "from ploomber import DAG\n",
    "from ploomber.tasks import NotebookRunner\n",
    "from ploomber.products import File\n",
    "from ploomber.executors import Parallel, Serial\n",
    "\n",
    "# to produce parameter grid\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# to create SQLite database\n",
    "from sklearn_evaluation import NotebookDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a14050",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "`NotebookDatabase` indexes the output of tagged cells. In this example, we're using Python scripts (and tag cells using `# %% tags=[\"some-tag\"]`), but the same concept applies for notebooks (`.ipynb`), [see here](https://docs.ploomber.io/en/latest/user-guide/faq_index.html#parameterizing-notebooks) to learn how to tag cells in `.ipynb` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading script\n",
    "data = \"\"\"\n",
    "# %% tags=[\"parameters\"]\n",
    "upstream = None\n",
    "product = None\n",
    "\n",
    "# %%\n",
    "from sklearn import datasets\n",
    "\n",
    "# %%\n",
    "ca_housing = datasets.fetch_california_housing(as_frame=True)\n",
    "df = ca_housing['frame']\n",
    "df.to_csv(product['data'], index=False)\n",
    "\"\"\"\n",
    "Path('data.py').write_text(data)\n",
    "\n",
    "# model fitting script\n",
    "model = \"\"\"\n",
    "# %% tags=[\"parameters\"]\n",
    "model = None\n",
    "params = None\n",
    "upstream = None\n",
    "product = None\n",
    "\n",
    "# %%\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# %%\n",
    "df = pd.read_csv(upstream['data']['data'])\n",
    "\n",
    "# %%\n",
    "X = df.drop('MedHouseVal', axis='columns')\n",
    "y = df.MedHouseVal\n",
    "\n",
    "# %%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# %% tags=[\"model\"]\n",
    "mod, _, attr = model.rpartition('.')\n",
    "reg = getattr(importlib.import_module(mod), attr)(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "# %% tags=[\"params\"]\n",
    "print(reg.get_params())\n",
    "\n",
    "# %% tags=[\"mse\"]\n",
    "y_pred = reg.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)\n",
    "\"\"\"\n",
    "Path('model.py').write_text(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f1365",
   "metadata": {},
   "source": [
    "## Pipeline declaration\n",
    "\n",
    "Create a pipeline using [Ploomber](https://docs.ploomber.io/en/latest/) and execute it in parallel.\n",
    "\n",
    "Note that if your models don't take long to run, using the `Serial` executor might be faster, since spinning up a new subprocess is expensive.\n",
    "\n",
    "Each experiment will create an output `.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel = True\n",
    "\n",
    "if parallel:\n",
    "    executor = Parallel()\n",
    "else:\n",
    "    executor = Serial(build_in_subprocess=False)\n",
    "\n",
    "\n",
    "dag = DAG(executor=executor)\n",
    "\n",
    "\n",
    "experiments = {\n",
    "    'sklearn.tree.DecisionTreeRegressor': ParameterGrid(dict(criterion=['squared_error', 'friedman_mse'], splitter=['best', 'random'], max_depth=[3, 5])),\n",
    "    'sklearn.linear_model.Lasso': ParameterGrid(dict(alpha=[1.0, 2.0, 3.0], fit_intercept=[True, False])),\n",
    "    'sklearn.linear_model.Ridge':ParameterGrid(dict(alpha=[1.0, 2.0, 3.0], fit_intercept=[True, False])), \n",
    "    'sklearn.linear_model.ElasticNet': ParameterGrid(dict(alpha=[1.0, 2.0, 3.0], fit_intercept=[True, False])), \n",
    "}\n",
    "\n",
    "papermill_params=dict(engine_name='embedded', progress_bar=False)\n",
    "\n",
    "# the embedded engine is more reliable\n",
    "task_data = NotebookRunner(Path('data.py'), {'nb': File('output/data.html'), 'data': File('output/data.csv')},\n",
    "               dag=dag, papermill_params=papermill_params)\n",
    "\n",
    "# generate one task per set of parameter\n",
    "for model, grid in experiments.items():\n",
    "    for i, params in enumerate(grid):\n",
    "        name = f'{model}-{i}'\n",
    "        task = NotebookRunner(Path('model.py'), File(f'output/models/{name}.ipynb'), dag=dag, name=name,\n",
    "                       papermill_params=papermill_params,\n",
    "                       params=dict(model=model, params=params))\n",
    "        task_data >> task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99304aea",
   "metadata": {},
   "source": [
    "## Pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total experiments to run\n",
    "len(dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baedfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiments\n",
    "dag.build(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20d086",
   "metadata": {},
   "source": [
    "## Indexing notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize db with notebooks in the outputs directory\n",
    "db = NotebookDatabase('nb.db', 'output/models/*.ipynb')\n",
    "\n",
    "# Note: pass update=True if you want to update the database if\n",
    "# the output notebook changes\n",
    "db.index(verbose=True, update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d69be",
   "metadata": {},
   "source": [
    "*Note: the `update` argument in `index()` was added in sklearn-evaluation version `0.7`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e6000",
   "metadata": {},
   "source": [
    "## Querying notebooks\n",
    "\n",
    "`NotebookDatabase` uses SQLite. Here we use [JupySQL](https://jupysql.readthedocs.io/en/latest/intro.html) to query our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d65845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load jupysql magic\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c2625",
   "metadata": {},
   "source": [
    "### Best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sqlite:///nb.db\n",
    "SELECT\n",
    "    path,\n",
    "    json_extract(c, '$.model') AS model,\n",
    "    json_extract(c, '$.mse') AS mse\n",
    "FROM nbs\n",
    "ORDER BY 3 ASC\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb4a322",
   "metadata": {},
   "source": [
    "*Note:* If using SQLite 3.38.0 (which ships with Python >=3.10) or higher, you can use the shorter `->>` operator:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    path,\n",
    "    c ->> '$.model' AS model,\n",
    "    c ->> '$.mse' AS mse\n",
    "FROM nbs\n",
    "ORDER BY 3 ASC\n",
    "LIMIT 3\n",
    "```\n",
    "\n",
    "See SQLite's [documentation](https://www.sqlite.org/json1.html#jptr) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbdf1c",
   "metadata": {},
   "source": [
    "### Average error by model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda420d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    json_extract(c, '$.model') AS model,\n",
    "    AVG(json_extract(c, '$.mse')) AS avg_mse\n",
    "FROM nbs\n",
    "GROUP BY 1\n",
    "ORDER BY 2 ASC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ea734",
   "metadata": {},
   "source": [
    "### DecisionTree by performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    json_extract(c, '$.model') AS model,\n",
    "    json_extract(c, '$.mse') AS mse,\n",
    "    json_extract(c, '$.params.max_depth') AS max_depth,\n",
    "    json_extract(c, '$.params.criterion') AS criterion,\n",
    "    json_extract(c, '$.params.splitter') AS splitter\n",
    "FROM nbs\n",
    "WHERE json_extract(c, '$.model') = 'sklearn.tree.DecisionTreeRegressor'\n",
    "ORDER BY mse ASC\n",
    "LIMIT 5"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
